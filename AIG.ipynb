{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Key-Feature Item Generator via Ollama (gpt-oss-2ob)\n",
    "---------------------------------------------------\n",
    "\n",
    "Requirements:\n",
    "    pip install requests\n",
    "\n",
    "Assumes:\n",
    "    - Ollama is running locally (default: http://localhost:11434)\n",
    "    - Model \"gemma3:4b\" is available in Ollama:\n",
    "        ollama pull gemma3:4b\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import textwrap\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. SYSTEM PROMPT FOR KEY-FEATURE MODELING\n",
    "# ============================================================\n",
    "\n",
    "SYSTEM_PROMPT = textwrap.dedent(\"\"\"\n",
    "You are an assessment expert and medical educator specializing in KEY-FEATURE (KF) test items for high-stakes exams.\n",
    "\n",
    "Definition and purpose:\n",
    "- Key-feature items present a concise clinical scenario.\n",
    "- They focus on a small number of critical decisions that strongly affect patient outcomes.\n",
    "- They emphasize clinical reasoning and prioritization, not simple recall.\n",
    "- Multiple questions (decisions) can be attached to a single scenario.\n",
    "\n",
    "General rules:\n",
    "- Always target the specified examinee level and exam context.\n",
    "- Use clear, concise, realistic clinical language.\n",
    "- Avoid ambiguous wording, double negatives, and trivial “test-wise” clues.\n",
    "- Ensure exactly one BEST answer per question when using single-best-answer MCQ.\n",
    "- Avoid real patient identifiers and unnecessary demographic details.\n",
    "- Avoid stereotypes, biased content, or stigmatizing language.\n",
    "- Base medical content on widely accepted, contemporary guidelines.\n",
    "\n",
    "Your tasks:\n",
    "- Generate new key-feature items from a provided key-feature statement and blueprint constraints.\n",
    "- Model parallel/variant items that share the same key feature but differ in surface features (e.g., age, setting, comorbidities).\n",
    "- Provide brief rationales for correct and incorrect options.\n",
    "- Provide metadata that is useful to psychometricians and SMEs (organ system, cognitive level, difficulty, etc.).\n",
    "\n",
    "Output rules:\n",
    "- Follow the requested JSON schema EXACTLY.\n",
    "- Return ONLY valid JSON (no extra comments, no Markdown, no explanations outside the JSON).\n",
    "- If the user’s instructions conflict with patient safety or accepted practice, follow the safest reasonable standard and record a note in the \"warnings\" field in the JSON.\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. USER PROMPT BUILDER\n",
    "# ============================================================\n",
    "\n",
    "def build_kf_user_prompt(\n",
    "    exam_name: str,\n",
    "    target_level: str,\n",
    "    clinical_setting: str,\n",
    "    key_feature_statement: str,\n",
    "    primary_decision_type: str,\n",
    "    organ_system: str,\n",
    "    typical_presentation: str,\n",
    "    cognitive_level: str,\n",
    "    intended_difficulty: str,\n",
    "    max_scenario_words: int = 150,\n",
    "    response_format: str = \"single_best_answer\",  # or \"short_answer\"\n",
    "    num_options: int = 5,\n",
    "    num_scenarios: int = 2,\n",
    "    questions_per_scenario: str = \"2-3\",\n",
    "    pitfalls: Optional[str] = None,\n",
    "    item_purpose: str = \"pretest\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build the user prompt text for key-feature item modeling.\n",
    "    \"\"\"\n",
    "\n",
    "    if pitfalls is None:\n",
    "        pitfalls = \"none\"\n",
    "\n",
    "    # Core instructions and blueprint\n",
    "    core = f\"\"\"\n",
    "TASK\n",
    "You will generate key-feature (KF) items for a high-stakes exam, following the schema and constraints below.\n",
    "\n",
    "EXAM CONTEXT\n",
    "- Exam name: {exam_name}\n",
    "- Target examinee level: {target_level}\n",
    "- Clinical setting: {clinical_setting}\n",
    "\n",
    "KEY FEATURE FOCUS\n",
    "- Key-feature statement (1–2 sentences):\n",
    "  {key_feature_statement}\n",
    "- Primary decision type:\n",
    "  {primary_decision_type}\n",
    "- Common pitfalls or enemy options to consider (optional):\n",
    "  {pitfalls}\n",
    "\n",
    "BLUEPRINT CONSTRAINTS\n",
    "- Organ system / content area: {organ_system}\n",
    "- Typical presentation: {typical_presentation}\n",
    "- Cognitive level: {cognitive_level}\n",
    "- Intended difficulty: {intended_difficulty}\n",
    "- Maximum scenario length: {max_scenario_words} words\n",
    "- Response format: {response_format}\n",
    "- Number of options per MCQ (if applicable): {num_options}\n",
    "\n",
    "ITEM MODELING REQUIREMENTS\n",
    "- Number of distinct clinical scenarios (cases): {num_scenarios}\n",
    "- For each scenario, number of questions (decisions): {questions_per_scenario}\n",
    "- Scenarios should:\n",
    "  - Share the same underlying key feature.\n",
    "  - Differ meaningfully in surface features (age, comorbidities, setting, etc.).\n",
    "- Avoid reusing identical wording across items except for technical terms.\n",
    "\n",
    "ADDITIONAL RULES\n",
    "- Use realistic but concise clinical details.\n",
    "- Avoid excessive lab lists; include only findings that matter for the key decision.\n",
    "- Ensure each question has exactly one best answer (for MCQ).\n",
    "- Distractors should be plausible and represent common errors or misconceptions, not obviously wrong options.\n",
    "\"\"\".strip()\n",
    "\n",
    "    # JSON schema / output format specification\n",
    "    json_schema = f\"\"\"\n",
    "OUTPUT FORMAT\n",
    "Return the result as VALID JSON ONLY, with NO additional text or comments.\n",
    "\n",
    "Use this exact JSON structure:\n",
    "\n",
    "{{\n",
    "  \"items\": [\n",
    "    {{\n",
    "      \"item_id\": \"KF_<short_descriptor>_<index>\",\n",
    "      \"scenario\": {{\n",
    "        \"title\": \"Short scenario title\",\n",
    "        \"text\": \"Full clinical scenario text (<= {max_scenario_words} words).\"\n",
    "      }},\n",
    "      \"questions\": [\n",
    "        {{\n",
    "          \"question_id\": \"Q1\",\n",
    "          \"lead_in\": \"Question that directly tests the key decision.\",\n",
    "          \"response_format\": \"{response_format}\",\n",
    "          \"options\": [\n",
    "            {{\n",
    "              \"label\": \"A\",\n",
    "              \"text\": \"Option text.\",\n",
    "              \"is_key\": true,\n",
    "              \"rationale\": \"Why this is the best answer based on the key feature and current guidelines.\"\n",
    "            }},\n",
    "            {{\n",
    "              \"label\": \"B\",\n",
    "              \"text\": \"Option text.\",\n",
    "              \"is_key\": false,\n",
    "              \"rationale\": \"Why this is incorrect (a common pitfall or misconception).\"\n",
    "            }}\n",
    "            // Add C, D, E as needed when response_format = \"single_best_answer\"\n",
    "          ],\n",
    "          \"short_answer_key\": null\n",
    "          // If response_format = \"short_answer\", set options = [] and use:\n",
    "          // \"short_answer_key\": \"Short model answer or key points.\"\n",
    "        }}\n",
    "        // Add Q2, Q3, etc., if multiple questions per scenario\n",
    "      ],\n",
    "      \"key_feature_statement\": \"Copy or paraphrase the key feature this item targets.\",\n",
    "      \"key_decision_type\": \"{primary_decision_type}\",\n",
    "      \"metadata\": {{\n",
    "        \"exam_name\": \"{exam_name}\",\n",
    "        \"target_level\": \"{target_level}\",\n",
    "        \"organ_system\": \"{organ_system}\",\n",
    "        \"clinical_setting\": \"{clinical_setting}\",\n",
    "        \"cognitive_level\": \"{cognitive_level}\",\n",
    "        \"intended_difficulty\": \"{intended_difficulty}\",\n",
    "        \"blueprint_tags\": [\n",
    "          \"core complaint or symptom\",\n",
    "          \"core disease entity\",\n",
    "          \"{primary_decision_type}\"\n",
    "        ],\n",
    "        \"item_purpose\": \"{item_purpose}\",\n",
    "        \"notes_for_reviewers\": \"Short note for SMEs or psychometricians.\",\n",
    "        \"warnings\": \"Describe any safety, guideline, or bias concerns. Use empty string if none.\"\n",
    "      }}\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "CONSTRAINTS\n",
    "- Do NOT include any text outside the JSON.\n",
    "- The JSON must be syntactically valid (no trailing commas, matching quotes/brackets).\n",
    "- Ensure every MCQ has exactly one option with \"is_key\": true (when using MCQs).\n",
    "- Ensure content is medically safe and aligned with contemporary guidelines for the specified context.\n",
    "\"\"\".strip()\n",
    "\n",
    "    return core + \"\\n\\n\" + json_schema\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. OLLAMA CALL WRAPPER\n",
    "# ============================================================\n",
    "\n",
    "def call_ollama_chat(\n",
    "    system_prompt: str,\n",
    "    user_prompt: str,\n",
    "    model: str = \"gemma3:4b\",\n",
    "    base_url: str = \"http://localhost:11434\",\n",
    "    timeout: int = 600,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Call Ollama /api/chat with a system + user prompt.\n",
    "    Returns the raw assistant content string.\n",
    "    \"\"\"\n",
    "    url = f\"{base_url}/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"stream\": False,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(url, json=payload, timeout=timeout)\n",
    "        resp.raise_for_status()\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        raise ConnectionError(\n",
    "            f\"Cannot connect to Ollama at {base_url}. \"\n",
    "            \"Please ensure Ollama is running: 'ollama serve'\"\n",
    "        )\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        raise RuntimeError(\n",
    "            f\"Ollama API error: {e}. \"\n",
    "            f\"Check if model '{model}' is installed: 'ollama list'\"\n",
    "        )\n",
    "    \n",
    "    data = resp.json()\n",
    "\n",
    "    # Expected Ollama chat response shape:\n",
    "    # { \"message\": { \"role\": \"assistant\", \"content\": \"...\" }, ... }\n",
    "    try:\n",
    "        content = data[\"message\"][\"content\"]\n",
    "    except KeyError:\n",
    "        raise RuntimeError(f\"Unexpected Ollama response format: {data}\")  # noqa: TRY003\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def generate_kf_items(\n",
    "    exam_name: str,\n",
    "    target_level: str,\n",
    "    clinical_setting: str,\n",
    "    key_feature_statement: str,\n",
    "    primary_decision_type: str,\n",
    "    organ_system: str,\n",
    "    typical_presentation: str,\n",
    "    cognitive_level: str,\n",
    "    intended_difficulty: str,\n",
    "    max_scenario_words: int = 150,\n",
    "    response_format: str = \"single_best_answer\",\n",
    "    num_options: int = 5,\n",
    "    num_scenarios: int = 2,\n",
    "    questions_per_scenario: str = \"2-3\",\n",
    "    pitfalls: Optional[str] = None,\n",
    "    item_purpose: str = \"pretest\",\n",
    "    model: str = \"gemma3:4b\",\n",
    "    base_url: str = \"http://localhost:11434\",\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    High-level wrapper:\n",
    "    - builds user prompt\n",
    "    - calls Ollama\n",
    "    - parses JSON into Python dict\n",
    "    \"\"\"\n",
    "    user_prompt = build_kf_user_prompt(\n",
    "        exam_name=exam_name,\n",
    "        target_level=target_level,\n",
    "        clinical_setting=clinical_setting,\n",
    "        key_feature_statement=key_feature_statement,\n",
    "        primary_decision_type=primary_decision_type,\n",
    "        organ_system=organ_system,\n",
    "        typical_presentation=typical_presentation,\n",
    "        cognitive_level=cognitive_level,\n",
    "        intended_difficulty=intended_difficulty,\n",
    "        max_scenario_words=max_scenario_words,\n",
    "        response_format=response_format,\n",
    "        num_options=num_options,\n",
    "        num_scenarios=num_scenarios,\n",
    "        questions_per_scenario=questions_per_scenario,\n",
    "        pitfalls=pitfalls,\n",
    "        item_purpose=item_purpose,\n",
    "    )\n",
    "\n",
    "    raw = call_ollama_chat(\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        user_prompt=user_prompt,\n",
    "        model=model,\n",
    "        base_url=base_url,\n",
    "    )\n",
    "\n",
    "    # Try to parse JSON\n",
    "    try:\n",
    "        parsed = json.loads(raw)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # If decoding fails, show the raw text so you can debug the prompt\n",
    "        print(\"⚠️ Failed to parse JSON from model output. Raw output:\\n\")\n",
    "        print(raw)\n",
    "        raise e\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. EXAMPLE USAGE\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Internal Medicine, STEMI initial management key feature\n",
    "    exam_name = \"Internal Medicine Certification\"\n",
    "    target_level = \"Final-year medical student\"\n",
    "    clinical_setting = \"Emergency department\"\n",
    "    key_feature_statement = (\n",
    "        \"Early recognition and immediate management of ST-elevation myocardial infarction \"\n",
    "        \"in a patient presenting with acute chest pain.\"\n",
    "    )\n",
    "    primary_decision_type = \"initial management\"\n",
    "    organ_system = \"cardiovascular\"\n",
    "    typical_presentation = (\n",
    "        \"Middle-aged adult with acute-onset chest pain, cardiovascular risk factors, \"\n",
    "        \"and typical ECG changes.\"\n",
    "    )\n",
    "    cognitive_level = \"application\"\n",
    "    intended_difficulty = \"moderate\"\n",
    "\n",
    "    try:\n",
    "        result = generate_kf_items(\n",
    "            exam_name=exam_name,\n",
    "            target_level=target_level,\n",
    "            clinical_setting=clinical_setting,\n",
    "            key_feature_statement=key_feature_statement,\n",
    "            primary_decision_type=primary_decision_type,\n",
    "            organ_system=organ_system,\n",
    "            typical_presentation=typical_presentation,\n",
    "            cognitive_level=cognitive_level,\n",
    "            intended_difficulty=intended_difficulty,\n",
    "            max_scenario_words=150,\n",
    "            response_format=\"single_best_answer\",\n",
    "            num_options=5,\n",
    "            num_scenarios=2,\n",
    "            questions_per_scenario=\"2-3\",\n",
    "            pitfalls=\"Misclassifying ACS as non-cardiac pain; delaying reperfusion therapy.\",\n",
    "            item_purpose=\"pretest\",\n",
    "            model=\"gemma3:4b\",\n",
    "            base_url=\"http://localhost:11434\",\n",
    "        )\n",
    "\n",
    "        # Pretty-print the JSON for quick inspection\n",
    "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(f\"Error during generation: {exc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
